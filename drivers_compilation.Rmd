---
title: "HAB Drivers Compilation"
author: "Amalia Handler"
date: "1/5/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

Compiling NLA 2007, 2012, and 2017 cyanobacteria data

```{r, include = FALSE, warning = FALSE, message = FALSE}
library(devtools)
library(dplyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(tidyr)
```

List of variables to compile

National lakes assessment (NLA)
* X_Chlorophyll a
* X_Cyanobacteria abundance
* X_Microcystin
* X_Cylindrospermopsin
* X_Total nitrogen
* X_Total phosphorus
* X_Dissolved organic carbon
* X_Turbidity
* X_pH
* X_Water temperature
* Dissolved oxygen
* X_Stratification
* X_HydroAP
* X_Evaporation/Inflow

PRISM
* X_Air temperature
* X_Precipitation

LakeCat
* X_Urban land cover
* X_Agricultural land cover
* X_Forested/natural land cover
* X_Wetland land cover
* Burned area
* X_Slope
* X_Elevation
* X_Wastewater treatment plants
* X_Runoff

Nutrient Inventory
* Nitrogen and phosphorus inputs
* Nitrogen and phosphorus excess

Lakemorpho
* X_Depth
* X_Fetch
* Surface area
* Perimeter

Load NLA data on cyanobacteria and water physiochemical characteristics
These data were compiled by Karen Blocksom


```{r}
# Read in data
# all_nla <- read.csv("NLA2007-2012-2017_LakeData_forHABs_4April2022.csv")

# Updated from Karen to include temperature data whenever a profile was collected
all_nla <- read.csv("NLA2007-2012-2017_LakeData_forHABs_12April2022.csv")

# Read in NLA UNIQUE_ID - NHDPlusV2 COMID crosswalk info from Marc
nla_lakecat <- read.csv("Integrated_NLA-LakeCat_COMID_Crosswalk.csv")

# Crosswalk document that contains the NLA SITE_ID and the NHDPlusV2 COMID
int_nla <- read.csv("NLA_Integrated_Design_Status_20190821.csv")

# Find the distinct UNIQUE_ID and COMIDs for the NLA-Lakecat crosswalk
unique_nla_lakecat <- nla_lakecat %>%
  select(UNIQUE_ID, COMID) %>%
  distinct()

# Define needed columns
nla_comid <- all_nla %>%
  select(SITE_ID, VISIT_NO, UNIQUE_ID, DSGN_CYCLE, DATE_COL, LAT_DD83, LON_DD83, 
         TEMPERATURE, STRATIFIED, AMMONIA_N, DOC, NTL, PTL, TURB, 
         NITRATE_N, PH, CHLA_RESULT, MICX, CYLSPER, B_G_DENS) %>%
  left_join(unique_nla_lakecat, by = "UNIQUE_ID")

# For sites still missing COMIDs, get from the alternate integrated NLA document
unique_nla_int <- int_nla %>%
  select(UNIQUE_ID, COMID) %>%
  distinct()

missing_coms <- nla_comid %>%
  filter(is.na(COMID)) %>%
  select(!COMID) %>%
  left_join(unique_nla_int, by = "UNIQUE_ID")

nla_all_coms <- nla_comid %>%
  filter(is.finite(COMID)) %>%
  bind_rows(missing_coms)

# Pivot from wide to long format
# Problem with some ammonium numbers recorded as "< 0.03", which cannot be coerced to a numeric value. Need to replace these values with something so that the column can be coerced to numeric type.
# Stratified column is a character currently and need to be changed to numeric type to convert to long format
nla_long <- nla_all_coms %>%
  mutate(STRATIFIED = ifelse(is.na(STRATIFIED), 0, 1)) %>%
  mutate(AMMONIA_N = as.numeric(replace(AMMONIA_N, AMMONIA_N == "< 0.03", NA))) %>%
  pivot_longer(TEMPERATURE:B_G_DENS, names_to = "ANALYTE", values_to = "RESULT")

# Where PH data was not measured in the lab, retrieve the top-most pH measurement from the profile
ph_profile <- nla_long %>%
  filter(ANALYTE == "PH") %>%
  filter(is.na(RESULT)) %>%
  select(-RESULT) %>%
  left_join(select(all_nla, VISIT_NO:DSGN_CYCLE, PH_FIELD), 
            by = c("UNIQUE_ID", "DSGN_CYCLE", "VISIT_NO")) %>%
  rename(RESULT = PH_FIELD)

# Remove the rows with missing pH data from the lab and add the field data and add the rows with pH data from the profile data
# Remove NA rows for cylindrospermopsin from 2007 and 2012 surveys because this analysis was not run during those years. Want any NA values present in the df to imply that the analysis was run, but result was below the detection limit.
# Add a units columns
nla_long <- nla_long %>%
  filter(!(ANALYTE == "PH" & is.na(RESULT))) %>%
  bind_rows(ph_profile) %>%
  filter(!(ANALYTE == "CYLSPER" & DSGN_CYCLE %in% c(2007, 2012))) %>%
  mutate(UNITS = case_when(ANALYTE == "TEMPERATURE" ~ "DEG_C",
                           ANALYTE == "STRATIFIED" ~ "Y/N_1/0",
                           ANALYTE %in% c("PTL", "MICX", "CYLSPER") ~ "UG/L",
                           ANALYTE == "TURB" ~ "NTU",
                           ANALYTE == "B_G_DENS" ~ "CELLS/ML",
                           ANALYTE == "PH" ~ "STD_UNITS",
                           ANALYTE %in% c("AMMONIA_N", "DOC", "NTL", "NITRATE_N", "CHLA_RESULT") ~ "MG/L"))

# Performing checks for missing data

# Lots of Nitrate data missing. Looks like everything below the reporting limit was listed as 0.005 mg/L in 2007 (RL = 0.02), but in 2012 (RL = 0.02) and 2017 (RL = 0.0025) ND for nitrate is reported as NA. 
nla_long %>%
  filter(ANALYTE == "NITRATE_N" & is.na(RESULT)) %>%
  nrow()

# Extract NLA observation ID information for joining with other data sources
nla_id <- nla_long %>%
  select(SITE_ID:COMID) %>%
  distinct()



```


Add evaporation to inflow ratio data from Emi Fergus and Renee Brooks


```{r}

# Load data
ratio0712 <- read.csv("NLA2007-2012_E-I_HYDRAP.csv")
ratio17   <- read.csv("NLA17_EI_estimates-Final.csv")

# Transform data to long form
ei0712 <- ratio0712 %>%
  select(SITE_ID, VISIT_NO, YEAR, E_I) %>%
  rename(DSGN_CYCLE = YEAR) %>%
  left_join(nla_id, by = c("SITE_ID", "VISIT_NO", "DSGN_CYCLE")) %>%
  rename(RESULT = E_I) %>%
  mutate(UNITS = "RATIO",
         ANALYTE = "EVAP_INFL")

ei17 <- ratio17 %>%
  select(SITE_ID, E_I, VISIT_NO) %>%
  mutate(DSGN_CYCLE = 2017) %>%
  left_join(nla_id, by = c("SITE_ID", "VISIT_NO", "DSGN_CYCLE")) %>%
  rename(RESULT = E_I) %>%
  mutate(UNITS = "RATIO",
         ANALYTE = "EVAP_INFL")
  
# Bind together 2007/2012 with 2017 data
evap_infl <- rbind(ei0712, ei17)

# Rearrange columns
evap_infl <- relocate(evap_infl, SITE_ID, VISIT_NO, UNIQUE_ID, DSGN_CYCLE, DATE_COL, LAT_DD83, LON_DD83, COMID, ANALYTE, RESULT, UNITS)

# From Emi and Renee: NA values mean that E/I was not calculated for some reason. Generally missing data or unrealistic E/I values were removed
# # Investigating missing values
# filter(ratio0712, is.na(E_I))
# filter(ratio17, is.na(E_I))
#
# write.csv(filter(ratio0712, is.na(E_I)), "missing2012-E_I.csv", row.names = F)
# write.csv(filter(ratio17, is.na(E_I)), "missing2017-E_I.csv", row.names = F)
# 
# filter(ei0712, is.na(COMID))
# filter(ei17, is.na(COMID))

# How many of the NLA sites are missing E/I data?
nrow(nla_id) - nrow(evap_infl)

# Note that most of the missing data comes from the site revisits
missing_check <- nla_all_coms %>%
  left_join(evap_infl, by = c("UNIQUE_ID","DSGN_CYCLE","VISIT_NO")) %>%
  filter(is.na(RESULT))

table(missing_check$VISIT_NO)

```


Add watershed metrics compiled by Marc Weber for all NLA lakes (in Lakecat and not in Lakecat)

```{r}
# Watershed metrics for NLA lakes compiled by Marc
wsmet <- read.csv("NLA_WatershedMetrics_NoDuplicates.csv")

# Select data I want to use and join with NLA data
wsmet <- wsmet %>%
  select(UNIQUE_ID, DSGN_CYCLE, lakemorpho_depth, RunoffWs, Precip_Minus_EVTWs, WWTPWs, starts_with("Pct"), Precip8110Ws, Tmean8110Ws, ElevWs, SlopeWs) %>%
  right_join(nla_id, by = c("UNIQUE_ID", "DSGN_CYCLE"))


```

Compile together NLA, NLA+, and LakeCat data

```{r}

habs <- nla_long %>%
  bind_rows(evap_infl) %>%
  select(!UNITS) %>%
  pivot_wider(names_from = ANALYTE, values_from = RESULT, values_fill = NA) %>%
  left_join(select(wsmet, UNIQUE_ID:SlopeWs), by = c("UNIQUE_ID", "DSGN_CYCLE")) %>%
  filter(!is.na(UNIQUE_ID))

# Convert to a sf object
habs_nars_all <- sf::st_as_sf(habs, coords = c('LON_DD83', 'LAT_DD83'), crs = 4269, remove = FALSE)

# Save the data as part of the package
# usethis::use_data(habs_nars_all, overwrite = T)

```



Load the lakecat data

```{r}

# Load in NLCD 2016 data
nlcd <- read.csv("Lakecat_NLCD2016.csv")

# Watershed slope information
slope <- read.csv("Lakecat_Slope.csv")

# Lake watershed elevation
elev <- read.csv("Lakecat_Elevation.csv")

# NLA integrated design status as of 2019-08-21. Crosswalks NLA site IDs with NHDPlusV2 lake COMIDs
nla_nhd <- read.csv("NLA_Integrated_Design_Status_20190821.csv")

# Combine the crosswalk df with the nla_id info to see if this fixes the problem of missing lakes with NLA-Lakecat join
master_id <- nla_nhd %>%
  select(COMID, SITE_ID, UNIQUE_ID, DSGN_CYCLE) %>%
  rename(NLA_YEAR = DSGN_CYCLE) %>%
  right_join(nla_id, by = c("SITE_ID", "NLA_YEAR"))

# Join with the NLA lake COMIDs included in the analysis
# This is losing about 185 lakes. Are these not in lakecat?
# Sounds like there may be issues in crosstalk for COMIDs listed in each NLA versus what was used for Lakecat
nla_lakecat <- nlcd %>%
  filter(COMID %in% nla_id$COMID) %>%
  mutate(agr_cat = PctHay2016Cat + PctCrop2016Cat,
         dev_cat = rowSums(select(., PctUrbOp2016Cat:PctUrbHi2016Cat)),
         nondev_cat = rowSums(select(., c(PctOw2016Cat, PctIce2016Cat, PctBl2016Cat:PctGrs2016Cat))),
         wet_cat = PctWdWet2016Cat + PctHbWet2016Cat,
         agr_ws = PctHay2016Ws + PctCrop2016Ws,
         dev_ws = rowSums(select(., PctUrbOp2016Ws:PctUrbHi2016Ws)),
         nondev_ws = rowSums(select(., c(PctOw2016Ws, PctIce2016Ws, PctBl2016Ws:PctGrs2016Ws))),
         wet_ws = PctWdWet2016Ws + PctHbWet2016Ws) %>%
  select(COMID, agr_cat:wet_ws)


# Which COMIDs are lacking from lakecat?
included_coms <- nlcd$COMID[nlcd$COMID %in% nla_id$COMID]
missing_coms  <- unique(nla_id$COMID[!(nla_id$COMID %in% included_coms)])

included_coms <- slope$COMID[slope$COMID %in% nla_id$COMID]
missing_coms  <- unique(nla_id$COMID[!(nla_id$COMID %in% included_coms)])

included_coms <- elev$COMID[elev$COMID %in% nla_id$COMID]
missing_coms  <- unique(nla_id$COMID[!(nla_id$COMID %in% included_coms)])

tmp <- nla_id[nla_id$COMID %in% missing_coms,]

unique(tmp$NLA_YEAR)

# Join NLCD with NLA HAB data
nla_nlcd <- left_join(nlahab, nlcd[,c(1,7:38)], by = "COMID")

# Save that data in an RDS file
saveRDS(nla_nlcd, "./compiled_nla17_nlcd16.rds")

# Read in saved RDS file
nla_nlcd <- readRDS("./compiled_nla17_nlcd16.rds")
```



Figures for presentations 

```{r}
# Presentations for CPHEA managers call, JASM, and PESD Science Seminar

# Get examples of climate, watershed, lake morphology, and water chemistry to illustrate how these data sources will be used in the conceptualized modeling project

# Climate data: MAT
mat <- read.csv("PRISM_1981_2010.csv")

# Watershed: Percent agricultural cover
# Lake morphology: Lake depth
wsmet <- read.csv("NLA_WatershedMetrics.csv")

# Response variables: Cyanobacteria cell abundance and microcystin concentration
# Water chemistry: Total nitrogen
pres <- nla_long %>%
  filter(ANALYTE %in% c("MICX", "B_G_DENS", "NTL")) %>%
  pivot_wider(id_cols = SITE_ID:COMID, names_from = ANALYTE, values_from = RESULT)

# Join mean temperature data with HABs data
pres <- mat %>%
  select(COMID, Tmean8110Ws) %>%
  right_join(pres, by = "COMID")

# Sum crop and hay percents to get agriculture
# Join to the HABs data
# Note there's a problem here with duplicated 
wsag <- wsmet %>%
  select(COMID, DSGN_CYCLE, lakemorpho_depth, PctHay2006Ws, PctCrop2006Ws, PctDecid2006Ws, PctConif2006Ws, PctMxFst2006Ws) %>%
  distinct() %>%
  mutate(PctAg2006Ws = PctHay2006Ws + PctCrop2006Ws,
         PctFst2006Ws = PctDecid2006Ws + PctConif2006Ws + PctMxFst2006Ws,
         .keep = "unused") %>%
  # This is a temporary fix to get data compiled. Will need to ask Marc about how to deal with repeat COMIDs
  distinct(COMID, DSGN_CYCLE, .keep_all = T)
  
# Join to presentation data
pres <- left_join(pres, wsag, by = c("COMID", "DSGN_CYCLE"))

expl_var <- "NTL"; xlabel <- 'Total Nitrogen (mg N/L)'; file_name <- "cyano_tn_biplot"
expl_var <- "Tmean8110Ws"; xlabel <- 'Mean Annual Temp (deg C)'; file_name <- "cyano_MAT_biplot"
expl_var <- "lakemorpho_depth"; xlabel <- 'Max Lake Depth (m)'; file_name <- "cyano_lakedepth_biplot"
expl_var <- "PctAg2006Ws"; xlabel <- 'Watershed Agriculture Land Use (%)'; file_name <- "cyano_ag_biplot"
expl_var <- "PctFst2006Ws"; xlabel <- 'Watershed Forest Cover (%)'; file_name <- "cyano_forest_biplot"



# Plot data
rev_biplots <- function(expl_var, file_name){
  
  ylabel <- 'Cyanobacteria (cells/mL + 1)'
  
  # Transform cyanobacteria data by adding 1 to make log transformation possible
  plot_data <- mutate(pres, tran_cyano = B_G_DENS + 1)
  
  # Order row my microcystin
  plot_data <- plot_data[order(plot_data$MICX, na.last = F),]
  
  plot_var <- plot_data[,match(expl_var, colnames(plot_data))]
  
  # For the Ag, need to add a very small number to the data to 
  # plot_var <- plot_var + 0.00001
  
  # For the Forest, need to add a very small number to the data to 
  # plot_var <- plot_var + 0.0001
  
  ggplot(data = plot_data, aes(x = plot_var, y = tran_cyano)) +
    geom_point(aes(color = MICX), stroke = .7, alpha = 0.7, size = 3) +
    # scale_x_continuous(trans = 'log10',
    #                    breaks = trans_breaks("log10", function(x) 10^x),
    #                    labels = trans_format("log10", math_format(10^.x))) +
    scale_y_continuous(trans = 'log10',
                       breaks = trans_breaks("log10", function(x) 10^x),
                       labels = trans_format("log10", math_format(10^.x))) +
    xlab(xlabel) +
    ylab(ylabel) +
    scale_color_gradient(low = "gold", high = 'red',
                         name = "Microcystin (ug/L)",
                         limits = c(0.1, 230),
                         trans = 'log10', 
                         breaks = c(0.1, 1, 10, 100),
                         labels = c("0.1", "1.0", "10", "100")) +
    theme_bw() +
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank())
  
  # Original size
  ggsave(paste0("./figures/",file_name,".png"), height = 3, width = 7, units = 'in', dpi = 600, bg = "transparent")
}




```




```{r, include = FALSE, warning = FALSE}

# Add 1 to cyanobacteria counts so that zero data will appear on log-transformed figures
nla_nlcd <- nla_nlcd %>%
  mutate(RESULT = ifelse(ANALYTE == "B_G_DENS", RESULT + 1, RESULT))

# Make a massive number of graphs
# ggplot(nla_nlcd, aes(y = RESULT, x = PctOw2016Cat)) +
#   geom_point(pch = 21, alpha = 0.5) +
#   facet_wrap(. ~ ANALYTE, scales = "free_y",  ncol = 4) +
#    scale_y_continuous(trans = 'log10',
#                        breaks = trans_breaks("log10", function(x) 10^x),
#                        labels = trans_format("log10", math_format(10^.x)))

# Make function
plot_nla_nlcd <- function(xvar, name){
  ggplot(nla_nlcd, aes(y = RESULT, x = xvar)) +
    geom_point(pch = 19, alpha = 0.5) +
    facet_wrap(. ~ ANALYTE, scales = "free_y",  ncol = 4) +
    xlab(name) +
    scale_y_continuous(trans = 'log10',
                       breaks = trans_breaks("log10", function(x) 10^x),
                       labels = trans_format("log10", math_format(10^.x)))
}

names <- colnames(nla_nlcd[c(8:39)])

nlcd_plots <- lapply(names, function(name){
  # Get col num
  colnum <- match(name, colnames(nla_nlcd))
  
  # Get column data
  x_var <- nla_nlcd[,colnum]
  
  # Make fig
  plot_nla_nlcd(x_var, name)
  
})

```

```{r, echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 2 * length(nlcd_plots)}

ggarrange(plotlist = nlcd_plots, ncol = 1)



```
