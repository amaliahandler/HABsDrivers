---
title: "drivers_analysis"
author: "Handler"
date: '2022-11-21'
output: html_document
editor_options: 
  chunk_output_type: console
---

Based on data compiled in drivers_compilation.Rmd

```{r setup, include=FALSE}
library(usethis)
library(devtools)
library(spmodel)
library(sf)
library(mapview)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)

# Load all data and functions from HABsDrivers package
load_all()

# Detailed guide to spmodel
# https://usepa.github.io/spmodel/articles/guide.html
```


Some additional variables:

```{r}
# Calculate the chlorophyll a associated with cyanobacteria
habs <- mutate(habs, CHLA_CYANO = CHLA_RESULT * BG_BIOVOL/PHYT_BIOVOL, .after = CHLA_RESULT)

# Add a 1/0 variable for detect/non-detect of nitrate
habs <- mutate(habs, NITRATE_DET = ifelse(is.na(NITRATE_N), 0, 1), .after = NITRATE_N)

# Replace non-detect values for nitrate with 0
habs <- mutate(habs, NITRATE_N = ifelse(is.na(NITRATE_N), 0, NITRATE_N))
```


Examine the predictor data for colinear variables
- TN and DOC
- Precip8110Ws and Precip_Minus_EVTWs and RunoffWs
- nondev_ws and agr_ws
- SlopeWs and ElevWs
- N_Total_Inputs, N_Surplus, P_Surplus (r > 0.90)


```{r}
cormat_pred <- cor(st_drop_geometry(select(habs, TEMPERATURE:P_Surplus)), use = "pairwise.complete.obs")

# cormat_pred <- cor(st_drop_geometry(select(habs, NTL, PTL, DOC, TURB, PH, TEMPERATURE, dev_ws, wet_ws, nondev_ws, agr_ws, lakemorpho_depth, Precip8110Ws, RunoffWs, Tmean8110Ws, ElevWs, SlopeWs, N_Surplus)), use = "pairwise.complete.obs")

corrplot.mixed(cormat_pred, upper = "ellipse", diag = "n", tl.pos = "lt", tl.col = "black", tl.srt = 45)

```


How much of the variation in the response variables is potentially explainable based on the spatial versus temporal variation?


```{r}
# Assess spatial (signal) to temporal (noise) in response variables
do.call(rbind, lapply(c("MICX", "B_G_DENS", "CHLA_RESULT", "CHLA_CYANO"), function(x){
  form <- as.formula(paste(x, " ~ 1 + (1|SITE_ID)"))
  df   <- habs
  
  if(x == "MICX"){
    df <- drop_na(df, MICX)
  }
  
  if(x == "B_G_DENS" | x == "MICX"){
    form <- as.formula(paste("log10(", x, "+ 1) ~ 1 + (1|SITE_ID)"))
  }
  
  if(x == "CHLA_RESULT"){
    form <- as.formula(paste("log10(", x, ") ~ 1 + (1|SITE_ID)"))
  }
  
  if(x == "CHLA_CYANO"){
    form <- as.formula(paste("log10(", x, ") ~ 1 + (1|SITE_ID)"))
  }
  
  mod         <- lme4::lmer(form, data = df, REML = T, verbose = F)
  site.var    <- as.numeric(lme4::VarCorr(mod)) 
  visit.var   <- attr(lme4::VarCorr(mod), "sc")^2
  sn          <- site.var / visit.var
  maxR2       <- sn/(sn + 1)
  return(data.frame(variable = x, maxR2))
}))


```

Model setup

```{r model setup}
# Function that creates the formula. When the response variable is cyanobacteria cell counts, add 1 and log-transform.
create_formula <- function(dep_var, ind_vars, log = F, interact = NULL){
  # Log = F
  form <- paste(dep_var, " ~ ", paste(ind_vars, collapse = " + "))
  # Log = T
  if(log == T){
    form <- paste("log10(", dep_var, "+ 1) ~ ", paste(ind_vars, collapse = " + "))
  }
  # Adding an interaction term
  if(is.null(interact) == F){
    form <- paste(form, "+", interact)
  }
  # Create formula object
  form_obj <- as.formula(form)
  return(form_obj)
}

# Create variable groups
all_vars     <- colnames(habs)[match("TEMPERATURE", colnames(habs)):match("P_Surplus", colnames(habs))]
dep_vars     <- c("B_G_DENS", "MICX", "CYLSPER", "CHLA_RESULT", "CHLA_CYANO", "BG_BIOVOL", "PHYT_BIOVOL")
all_ind_vars <- all_vars[!all_vars %in% dep_vars]

# Dropping non-developed area of the watershed due to issues of colinearity with developed area. Also dropping nitrate data since it is missing for a large number of observations.
# all_ind_vars <- all_ind_vars[!all_ind_vars %in% c("nondev_ws", "NITRATE_N")]
# Dropping non-developed area of the watershed due to issues of colinearity with developed area.
all_ind_vars <- all_ind_vars[!all_ind_vars == "nondev_ws"]

# NLA water variables
nla_ind_vars <- c("TEMPERATURE", "MAXDEPTH", "STRATIFIED", "AMMONIA_N", "DO_SURF", "DOC", "NTL", "PTL", "TURB", "NITRATE_N", "NITRATE_DET", "PH", "EVAP_INFL", "D_EXCESS")
  
# All non-NLA variables
non_nla_vars <- all_ind_vars[!all_ind_vars %in% nla_ind_vars]

# All nutrient inventory variables
nni_vars <- colnames(habs)[match("N_AG_N2O_INPUTS", colnames(habs)):match("P_Surplus", colnames(habs))]

```

Helper to visualize fitted versus observed values from the model results

```{r}
vis_fit <- function(dep_var, splm_obj, file_name = NULL, width = 5, height = 4, dpi = 400){
  
  # Augment the splm object with the .fitted data
  aug <- augment(splm_obj) |>
    rename(obs = 1)
  
  # Title the figure according to response variable modeled
  name <- "Log10(Cyanobacteria + 1)"
  
  if(dep_var == "MICX_DET"){name = "Probability Microcystin Presence/Absence"}
  if(dep_var == "MICX"){name = "Log10(Microcystin Concentration)"}
  
  fig <- NULL
  
  # Construct the figure, continuous case
  if(dep_var == "MICX" | dep_var == "B_G_DENS"){
    
    # Max values for the axes
    max_val <- max(pull(aug, obs), pull(aug, .fitted))
    
    fig <- ggplot(data = aug, aes(x = obs, y = .fitted)) + 
      geom_point(color = "blue", alpha=0.3) + 
      xlim(0, max_val) + ylim(0, max_val) +
      xlab("Observed") +
      ylab("Fitted") +
      ggtitle(name)
  }
  
  # Binary case
  if(dep_var == "MICX_DET"){
    levels(aug$obs) <- c("Absent", "Present")
    
    fig <- ggplot(data = aug, aes(x = obs, y = .fitted)) + 
      geom_boxplot(color = "blue", alpha = 0.3) + 
      xlab("Observed") +
      ylab("Fitted") +
      ggtitle(name)
  }
  
  # Save the figure
  if(is.null(file_name) == FALSE){ggsave(paste0("./figures/", file_name), height = height, width = width, dpi = dpi, units = "in")}
  
  # Print a correlation test
  fit_test <- NULL
  if(dep_var == "MICX_DET"){fit_test = pROC::auc(aug$obs, aug$.fitted)}
  if((dep_var == "MICX" | dep_var == "B_G_DENS")){fit_test = cor.test(pull(aug, obs), pull(aug, .fitted))}
  
  print(fit_test)
  
  return(fig)
}

```


Experiment with some spatial models


```{r cyano models}

# 2024-01-24 Models on cyanobacteria cell counts using all available explanatory variables
# Lessons learned: 

# There is a lot of missing biovolume data. Enough that I switched back to cyano count data. Will need to check with Karen about why so much data is missing for this parameter.

# TP isn't important unless TN is removed from the model. These two variables are likely highly colinear. Both TN and TP come out as important in the model if one of them has an interaction with three aggregated ecoregions. With TN*AG_ECO3, both the plains and western mountains come out as important plus the interaction between the plains and TN. With TP*AG_ECO3, the plains are important alone and there is an interaction between the plains and the western mountains and TP. When the interaction term is present between TN and the ecoregions, the effect of precipitation 30 yr normals and EVAP/INFL is lessened. However, the model with the lowest AIC lacks the interaction term. 

# Watershed mean slope and elevation were coming out as highly related to cyanos, but the effect diminished with the addition of the ecoregional data as a categorical variable. It's likely that slope and elevation were acting as proxies for the western mountain and xeric ecoregions that have much lower cyanos compared to other regions. Therefore, decided to include just the three aggregated ecoregions. 

# Also, the ecoregions are included as a fixed rather than a random effect now since the effect seems to be important and not an artifact of the NLA design. 

# Might consider playing around with having an ecoregional interaction term with some of the variables. This seemed promising when there was an interaction between ecoregion and TN, but not with any other variables (tried temp and agriculture). 

# The 30-year climate normals for temp and precip always outperformed the monthly means in which the sample was collected and the water temperature at the time of sampling. This is likely at least in part to the inclusion of a survey year random effect, but when survey year is removed and monthly means included, the model performs substantially worse.

# Note that in some preliminary tests the spatial regression models are explianing ~40-55% of the variation cyano count data while the random forest model explains ~28%.

# Experimenting with including nitrate in the models. Nitrate detection and concentration are negatively associated with cyanobacteria. TN, nitrate detected, and nitrate concentration can all be included in the same model. These three variables can also be included with TP and it comes out as important, though negatively correlated with cyanos which is confusing. Note that the addition of nitrate and ammonium variables increases the AIC relative to a model that only includes TN.

# Switched out E/I for d-excess following a conversation with Renee Brooks. D-excess is a measure of how much how evaporated the water is. When water is still, there is a higher evaporation rate. So d-excess can be thought of as a proxy for how long water has been sitting around evaporating. When d-excess is low, the water is more evaporated. It seems to have a stronger relationship with cyanos.

dep_var  <- "B_G_DENS"
mod_vars <- c("NTL","NITRATE_N", "NITRATE_DET", "AMMONIA_N", "DOC", "PH", "Precip8110Ws", "Tmean8110Ws", "D_EXCESS", "MAXDEPTH", "agr_ws", "AG_ECO3")
cyano    <- splm(create_formula(dep_var, mod_vars, log = T),
                 data = filter(drop_na(habs, all_of(dep_var), all_of(mod_vars))),
                 spcov_type = "exponential",
                 random = ~ DSGN_CYCLE + UNIQUE_ID,
                 local = T)

cyano_pred <- filter(drop_na(habs, all_of(dep_var), all_of(mod_vars)))

# cyano_pred$pred <- predict(cyano, newdata = cyano_pred)

cyano_loocv <- loocv(cyano, cv_predict = TRUE)

cyano_pred$preds <- cyano_loocv$cv_predict

max_val <- max(log10(cyano_pred$B_G_DENS +1), cyano_pred$preds)
name <- "Log10(Cyanobacteria + 1)"

fig <- ggplot(data = cyano_pred, aes(x = preds, y = log10(B_G_DENS +1))) +
  geom_point(color = "blue", alpha=0.3) +
  xlim(0, max_val) + ylim(0, max_val) +
  ylab("Observed") +
  xlab("Fitted") +
  ggtitle(name)
ggsave(paste0("./figures/", "Model Fit_Cyano.jpg"), height = 4, width = 5, dpi = 400, units = "in")

# cyano_c <- splm(create_formula(dep_var, mod_vars, log = T, interact = "AG_ECO3*PTL"),
#                  data = drop_na(habs, all_of(dep_var), all_of(mod_vars)),
#                  spcov_type = "exponential",
#                  random = ~ DSGN_CYCLE + UNIQUE_ID,
#                  local = T)

summary(cyano)
varcomp(cyano)

# cyano1 <- cyano

# Best model so far (?)
dep_var  <- "B_G_DENS"
mod_vars <- c("NTL","DOC", "PH", "Precip8110Ws", "Tmean8110Ws", "EVAP_INFL", "MAXDEPTH", "agr_ws", "AG_ECO3")
cyano_local_f <- splm(create_formula(dep_var, mod_vars, log = T),
                 data = drop_na(habs, all_of(dep_var), all_of(mod_vars)),
                 spcov_type = "exponential",
                 random = ~ DSGN_CYCLE + UNIQUE_ID,
                 local = F)

# Save the model since it takes so long to run
# saveRDS(cyano_local_f, "./data/cyano_cell_density_model.rds")
# cyano_local_f <- readRDS("./data/cyano_cell_density_model.rds")

summary(cyano_local_f)
varcomp(cyano_local_f)

vis_fit(dep_var, cyano_local_f, file_name = "Model Fit_Cyano.jpg")

```


Models for microcystin detection (presence/absence)


```{r}
# Create the binary microcystin variable
habs <- mutate(habs, MICX_DET = factor(ifelse(is.finite(MICX), 1, 0)))

dep_var  <- "MICX_DET"

run_micx <- function(mod_vars, int = NULL){
  spglm(create_formula(dep_var, mod_vars, log = F, interact = int),
                family = "binomial",
                data = drop_na(habs, all_of(dep_var), all_of(mod_vars)),
                spcov_type = "exponential",
                random = ~ DSGN_CYCLE + UNIQUE_ID,
                local = F)
}

# Lessons learned
# These models take substantially longer to run than the linear models and the estimated covariates are most unstable when run using approximation methods (local = T).

# The temperature and precip data never seem to be important to this model.

# Soil erodibility (Kf) is inversely associated with microcystin detection?

# These were all run with local = T
micx1 <- run_micx(mod_vars = c("NTL","PTL", "DOC", "PH", "dev_ws", "agr_ws", "KffactWs", "precip_mean_month", "TEMPERATURE", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

micx2 <- run_micx(mod_vars = c("NTL","PTL", "DOC", "PH", "dev_ws", "agr_ws", "wet_ws", "KffactWs", "precip_mean_month", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"), int = "PTL*AG_ECO3")

micx3 <- run_micx(mod_vars = c("NTL","PTL", "DOC", "PH", "dev_ws", "agr_ws", "KffactWs", "precip_mean_month", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"), int = "NTL*AG_ECO3")

micx4 <- run_micx(mod_vars = c("NTL", "DOC", "PH", "dev_ws", "agr_ws", "KffactWs", "precip_mean_month", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

micx5 <- run_micx(mod_vars = c("NTL", "PH", "dev_ws", "agr_ws", "KffactWs", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

# Set local = F here since it seems like the estimates are changing quite a bit between estimated runs
micx6 <- run_micx(mod_vars = c("NTL", "PH", "dev_ws", "agr_ws", "KffactWs", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

# Back to local = T
micx7 <- run_micx(mod_vars = c("NTL", "PH", "dev_ws", "agr_ws", "KffactWs", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "RunoffWs", "AG_ECO3"))

# Best fit so far? Hard to know when running models using approximation methods.
micx8 <- run_micx(mod_vars = c("NTL", "PH", "dev_ws", "agr_ws", "KffactWs", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

# Take out developed area and monthly temperature 
micx9 <- run_micx(mod_vars = c("NTL", "PH", "agr_ws", "KffactWs", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))

summary(micx6)
varcomp(micx6)

aug_micx <- augment(micx5)

pROC::auc(aug_micx$MICX_DET, aug_micx$.fitted)

vis_fit(dep_var, micx6, file_name = "Model Fit_Micx_Det.jpg")

# Best fit so far? Run with local = F.
micx_local_f <- run_micx(mod_vars = c("NTL", "PH", "dev_ws", "agr_ws", "KffactWs", "temp_mean_month", "BFIWs", "MAXDEPTH", "EVAP_INFL", "lakemorpho_fetch", "AG_ECO3"))
# Note that temperature has a negative relationship here

# Save the model since it takes so long to run
saveRDS(cyano_local_f, "./data/micx_dectect_model.rds")
# cyano_local_f <- readRDS("./data/micx_dectect_model.rds")

vis_fit(dep_var, micx_local_f, file_name = "Model Fit_Micx_Det.jpg")
summary(micx_local_f)
varcomp(micx_local_f)

```


Models for microcystin concentration, when present


```{r}
dep_var  <- "MICX"

run_micxlm <- function(mod_vars, int = NULL){
  splm(create_formula(dep_var, mod_vars, log = T, interact = int),
                data = drop_na(habs, all_of(dep_var), all_of(mod_vars)),
                spcov_type = "exponential",
                random = ~ DSGN_CYCLE + UNIQUE_ID,
                local = F)
}

# Lessons learned
# Similarly to cyanobacteria cell counts, TP only becomes important when TN is removed as a covariate, signaling that these are colinear. But interesting that turbidity is important with this model in addition to TN. Would have expected these variables to be colinear so as not to overlay with each other.

micxlm1 <- run_micxlm(mod_vars = c("NTL","PTL", "DOC", "PH", "wet_ws", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"))

micxlm2 <- run_micxlm(mod_vars = c("NTL","PTL", "DOC", "PH", "wet_ws", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"), int = "NTL*AG_ECO3")

micxlm3 <- run_micxlm(mod_vars = c("NTL","PTL", "DOC", "PH", "wet_ws", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"), int = "PTL*AG_ECO3")

micxlm4 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "wet_ws", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"))

micxlm5 <- run_micxlm(mod_vars = c("PTL", "DOC", "PH", "wet_ws", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"))

micxlm6 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "RunoffWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length", "AG_ECO3"))

micxlm7 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "EVAP_INFL", "MAXDEPTH", "lakemorpho_shoreline.length"))

micxlm8 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "TEMPERATURE", "BFIWs", "EVAP_INFL", "MAXDEPTH"))

micxlm9 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "Tmean8110Ws", "BFIWs", "EVAP_INFL", "MAXDEPTH"))

micxlm10 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "Tmean8110Ws", "BFIWs", "EVAP_INFL", "lakemorpho_fetch"))

micxlm11 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "agr_ws", "precip_mean_month", "Tmean8110Ws", "EVAP_INFL"))

# Perhaps best fit model?
micxlm12 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "TURB", "agr_ws", "precip_mean_month", "Tmean8110Ws", "EVAP_INFL"))

micxlm13 <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "TURB", "agr_ws", "precip_mean_month", "Tmean8110Ws", "EVAP_INFL", "ElevWs"))

# Run with local = F
micxlm_local_f <- run_micxlm(mod_vars = c("NTL", "DOC", "PH", "TURB", "agr_ws", "precip_mean_month", "Tmean8110Ws", "EVAP_INFL"))

summary(micxlm_local_f)
varcomp(micxlm_local_f)

vis_fit(dep_var, micxlm_local_f, file_name = "Model Fit_Micx_Conc.jpg")

```



Random forest experimenting

```{r}
# A good tutorial introducing random forest https://uc-r.github.io/random_forests

# Create a binary for microcystin detections
# habs <- mutate(habs, MICX_DET = factor(ifelse(is.finite(MICX), 1, 0)))

# Dependent variable 
dep_var <- "MICX"

# How much missingness is there in the data?
missing_data <- habs |>
  st_drop_geometry() |>
  summarize_all(funs(sum(is.na(.)))) |>
  pivot_longer(SITE_ID:UUS_L4NAME, names_to = "variable", values_to = "num_missing")

# Examine if the error stabilizes with the number of trees
m1 <- randomForest::randomForest(
  formula = create_formula(dep_var, all_ind_vars, log = F),
  data = drop_na(habs, all_of(dep_var), all_of(all_ind_vars))
)
plot(m1)

# Tune the mTry parameter
na_free <- drop_na(habs, all_of(dep_var), all_of(all_ind_vars))

m2 <- randomForest::tuneRF(
  x          = st_drop_geometry(na_free[all_ind_vars]),
  y          = na_free$MICX,
  ntreeTry   = 500,
  mtryStart  = 4,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = FALSE      # to not show real-time progress 
)

# hyperparameter grid search
hyper_grid <- expand.grid(
  mtry       = seq(4, 16, by = 2),
  node_size  = seq(2, 8, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger::ranger(
    formula         = create_formula(dep_var, all_ind_vars, log = F),
    data            = st_drop_geometry(drop_na(habs, all_of(dep_var), all_of(all_ind_vars))), 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

# Which set of parameters yields the lowest OOB RMSE?
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)

# Check expected error for optimal set of hyperparameters
OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger <- ranger::ranger(
    formula         = create_formula(dep_var, all_ind_vars, log = F),
    data            = st_drop_geometry(drop_na(habs, all_of(dep_var), all_of(all_ind_vars))), 
    num.trees       = 500,
    mtry            = 8,
    min.node.size   = 4,
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

imp <- tibble(var = names(optimal_ranger$variable.importance), var_imp = optimal_ranger$variable.importance)

imp %>% 
  dplyr::arrange(desc(var_imp)) %>%
  ggplot(aes(x = reorder(var, var_imp), y = var_imp)) +
  geom_col() +
  coord_flip() +
  xlab("Variable") + ylab("Variable Importance") +
  ggtitle("NLA '07,'12,'17_All Variables")

# ggsave("./figures/Variable importance_NLA'07,'12,'17_all.png", dpi = 300, width = 5, height = 5)


# Given the parameter tuning, now pass the data to spmodel
modRF <- splmRF(create_formula(dep_var, all_ind_vars, log = T),
                data = drop_na(habs, all_of(dep_var), all_of(all_ind_vars)),
                spcov_type = "exponential",
                random = ~ DSGN_CYCLE + UNIQUE_ID,
                local = TRUE,
                num.trees       = 500,
                mtry            = 8,
                min.node.size   = 4,
                sample.fraction = .8,
                importance = "impurity")

modRF.imp <- tibble(var = names(modRF$ranger$variable.importance), var_imp = modRF$ranger$variable.importance)

modRF.imp %>% 
  dplyr::arrange(desc(var_imp)) %>%
  dplyr::top_n(25) %>%
  ggplot(aes(x = reorder(var, var_imp), y = var_imp)) +
  geom_col() +
  coord_flip() +
  xlab("Variable") + ylab("Variable Importance")

# ggsave("./figures/Variable importance_spMod_NLA'07,'12,'17_all.png", dpi = 300, width = 5, height = 5)

obs <- habs |>
  drop_na(all_of(dep_var), all_of(all_ind_vars)) |>
  st_drop_geometry() |>
  mutate(obs = log10(B_G_DENS +1)) |>
  pull(obs)

plot(optimal_ranger$predictions, obs)
cor.test(optimal_ranger$predictions, log10(tmp+1))

mod <- modRF$ranger$predictions

plot(obs, mod, ylim = c(0, max(mod, obs)), xlim = c(0, max(mod, obs)))
cor.test(mod, obs)

  
```


Try random forest with large collection of data from Robert Sabo


```{r}
# All data from Robert (untransformed)
nni <- readr::read_csv("NLA07-12_NutrientInventory_Data.csv")

# Have to break out the month and day of the compiled HABs data
comp <- habs |>
  mutate(Month = as.numeric(format(as.Date(DATE_COL, format = "%m/%d/%Y"), "%m")),
         Day = as.numeric(format(as.Date(DATE_COL, format = "%m/%d/%Y"), "%d")),
         Year = as.numeric(as.character(DSGN_CYCLE))) |>
  # select(SITE_ID, Year, Month, Day, B_G_DENS, TEMPERATURE, DOC, TURB, PH, EVAP_INFL, lakemorpho_depth, ElevWs, SlopeWs) 
  # Remove redundant variables
  select(-NTL, -PTL, -RunoffWs, -LAT_DD83, -LON_DD83, -DATE_COL, -DSGN_CYCLE, -VISIT_NO, -COMID, -MICX, -CHLA_RESULT, -CYLSPER, -UNIQUE_ID)

# Merge with cyanobacteria counts
comp <- left_join(nni, comp, by = c("SITE_ID", "Year", "Month", "Day"))

# Create a vector of the independent variables
nni_vars <- colnames(comp)[c(9:91,93:(length(colnames(comp))-1))] #

# Examine if the error stabilizes with the number of trees
m1 <- randomForest::randomForest(
  formula = create_formula(dep_var, nni_vars, log = T),
  data = drop_na(comp, all_of(dep_var), all_of(nni_vars))
)
plot(m1)

# Tune the mTry parameter
na_free <- drop_na(comp, all_of(dep_var), all_of(nni_vars))

m2 <- randomForest::tuneRF(
  x          = st_drop_geometry(na_free[nni_vars]),
  y          = log10(na_free$B_G_DENS + 1),
  ntreeTry   = 500,
  mtryStart  = 4,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = FALSE      # to not show real-time progress 
)

# hyperparameter grid search
hyper_grid <- expand.grid(
  mtry       = seq(25, 35, by = 2),
  node_size  = seq(3, 9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger::ranger(
    formula         = create_formula(dep_var, nni_vars, log = T),
    data            = st_drop_geometry(drop_na(comp, all_of(dep_var), all_of(nni_vars))), 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123,
    num.threads     = 8
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

# Which set of parameters yields the lowest OOB RMSE?
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(15)

# Check expected error for optimal set of hyperparameters
OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger <- ranger::ranger(
    formula         = create_formula(dep_var, nni_vars, log = T),
    data            = st_drop_geometry(drop_na(comp, all_of(dep_var), all_of(nni_vars))), 
    num.trees       = 500,
    mtry            = 29,
    min.node.size   = 3,
    sample.fraction = .8,
    num.threads     = 8, 
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

optimal_ranger <- ranger::ranger(
  formula         = create_formula(dep_var, nni_vars, log = T),
  data            = drop_na(comp, all_of(dep_var), all_of(nni_vars)), 
  num.trees       = 500,
  mtry            = 29,
  min.node.size   = 3,
  sample.fraction = .8,
  num.threads     = 8, 
  importance      = 'impurity')

imp <- tibble(var = names(optimal_ranger$variable.importance), var_imp = optimal_ranger$variable.importance)

imp %>% 
  dplyr::arrange(desc(var_imp)) %>%
  dplyr::top_n(25) %>%
  ggplot(aes(x = reorder(var, var_imp), y = var_imp)) +
  geom_col() +
  coord_flip() +
  xlab("Variable") + ylab("Variable Importance") +
  ggtitle("NLA '07,'12_All Variables")

ggsave("./figures/Variable importance_NLA'07,'12_all.png", dpi = 300, width = 5, height = 5)

########################################################

# Have to break out the month and day of the compiled HABs data
comp <- habs |>
  mutate(Month = as.numeric(format(as.Date(DATE_COL, format = "%m/%d/%Y"), "%m")),
         Day = as.numeric(format(as.Date(DATE_COL, format = "%m/%d/%Y"), "%d")),
         Year = as.numeric(as.character(DSGN_CYCLE))) |>
  select(-NTL, -PTL, -RunoffWs) |>
  right_join(nni, by = c("SITE_ID", "Year", "Month", "Day")) # |>
  # filter(!duplicated(UNIQUE_ID)) # If running with unique observations

# Investigate how the year random effect interacts with some data that is specific to the sample year
nni_sub <- c(all_vars, "LSTAnomaly_YrMean", "NPP_YrMean", "Precip_YrMean", "Tmean_YrMean")

nni_no_re_no_sp <- splm(create_formula(dep_var, nni_sub, log = T),
                     data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                     spcov_type = "none", 
                     local = TRUE)

nni_no_re <- splm(create_formula(dep_var, nni_sub, log = T),
                     data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                     spcov_type = "exponential", 
                     local = TRUE)

nni_re_site <- splm(create_formula(dep_var, nni_sub, log = T),
                         data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                         spcov_type = "exponential",
                         random = ~  UNIQUE_ID,
                         local = TRUE)

nni_re_year <- splm(create_formula(dep_var, nni_sub, log = T),
                         data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                         spcov_type = "exponential",
                         random = ~  DSGN_CYCLE,
                         local = TRUE)

nni_unnest_re <- splm(create_formula(dep_var, nni_sub, log = T),
                       data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                       spcov_type = "exponential",
                       random = ~ DSGN_CYCLE + UNIQUE_ID,
                       local = TRUE)

nni_nest_re <- splm(create_formula(dep_var, nni_sub, log = T),
                       data = drop_na(comp, all_of(dep_var), all_of(nni_sub)),
                       spcov_type = "exponential",
                       random = ~ (DSGN_CYCLE / UNIQUE_ID),
                       local = TRUE)

# Compare model with no spatial component, with spatial component, random effect for site alone, random effect for year along, random effect for site and year unnested, random effect for site nested within year.
# How does the AIC and R2 change with these model configurations
glances(nni_no_re_no_sp,
        nni_no_re,
        nni_re_site,
        nni_re_year,
        nni_unnest_re,
        nni_nest_re)
# Nested random effects had the lowest AIC and R2 followed by unnested random effects
# About the same amount of variation is explained with no random effects

optimal_ranger <- ranger::ranger(
  formula         = create_formula(dep_var, nni_sub, log = T),
  data            = drop_na(comp, all_of(dep_var), all_of(nni_sub)), 
  num.trees       = 500,
  mtry            = 8,
  min.node.size   = 3,
  sample.fraction = .8,
  num.threads     = 8, 
  importance      = 'impurity')

imp <- tibble(var = names(optimal_ranger$variable.importance), var_imp = optimal_ranger$variable.importance)

imp %>% 
  dplyr::arrange(desc(var_imp)) %>%
  dplyr::top_n(25) %>%
  ggplot(aes(x = reorder(var, var_imp), y = var_imp)) +
  geom_col() +
  coord_flip() +
  xlab("Variable") + ylab("Variable Importance") +
  ggtitle("NLA '07,'12_All Variables")

ggsave("./figures/Variable importance_NLA'07,'12_with annual.png", dpi = 300, width = 5, height = 5)


```


